{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coding:utf-8\n",
    "#稳定函数模块\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "import time\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split,StratifiedKFold\n",
    "from sklearn.preprocessing import Binarizer\n",
    "from sklearn.metrics import roc_auc_score,classification_report,f1_score,accuracy_score,recall_score\n",
    "\n",
    "\n",
    "\n",
    "#二值化处理，传入np.array或list，输出二值化后的同类型数据\n",
    "def binarize(result):\n",
    "    for i in range(len(result)):\n",
    "        if result[i]>=0.5:\n",
    "            result[i]=1\n",
    "        else:\n",
    "            result[i]=0\n",
    "    return result\n",
    "#样例\n",
    "#result = binarize(result)\n",
    "\n",
    "#计算F1score的函数,传入预测结果和正确的结果，返回F1_score\n",
    "def cal_f1(result_valid,lb_valid):\n",
    "    TP,FP,FN = 0,0,0\n",
    "    for i in range(len(lb_valid)):\n",
    "        if result_valid[i] ==1 and lb_valid[i] == 1:\n",
    "            TP +=1\n",
    "        if result_valid[i]==1 and lb_valid[i]==0:\n",
    "            FP +=1\n",
    "        if result_valid[i] == 0 and lb_valid[i]==1:\n",
    "            FN +=1\n",
    "    precision = TP/(TP+FP)\n",
    "    recall = TP/(TP+FN)\n",
    "    F1 = 2*precision*recall/(precision + recall)\n",
    "    print('precision:',precision)\n",
    "    print('recall:',recall)\n",
    "    print('F1:',F1)\n",
    "    return True\n",
    "#样例\n",
    "#cal_f1(result_valid,lb_valid)\n",
    "\n",
    "#测试集预测,传入lgb_model、sid以及测试集特征，直接生成csv文件并返回True\n",
    "#如果需要二值化，则多一条binarize = True\n",
    "def predict(bst,sid,test,outputfile,binarize = False):\n",
    "    result = bst.predict(test)\n",
    "    if binarize==True:\n",
    "        result = binarize(list(result))\n",
    "    #进行拼接并生成最终文件\n",
    "    result = pd.DataFrame(result)\n",
    "    final = pd.concat([sid,result], axis=1, join='outer')\n",
    "    final.columns = ['sid','label']\n",
    "    final.to_csv(outputfile,index = None)\n",
    "    return True\n",
    "#使用样例\n",
    "#predict(bst,sid,test,'lgb.csv',binarize = False)\n",
    "\n",
    "#lgb训练log作图，传入metric_dict，自动生成图像，并在最后一个点处标记数据\n",
    "def picture_lgb_loss(metric_dict):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(metric_dict['valid_0']['auc'])\n",
    "    plt.plot(metric_dict['valid_0']['binary_logloss'])\n",
    "    plt.title('lgb-naive log')\n",
    "    plt.ylabel('Loss&AUC')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['val_auc','valid_loss'], loc='right')\n",
    "    \n",
    "    final = len(metric_dict['valid_0']['auc'])\n",
    "\n",
    "    plt.text(final, metric_dict['valid_0']['auc'][final-1] ,\"final:\"+str(metric_dict['valid_0']['auc'][final-1])\n",
    "             , ha='center', va='bottom', fontsize=10)\n",
    "    plt.text(final, metric_dict['valid_0']['binary_logloss'][final-1] ,\"final:\"+str(metric_dict['valid_0']['binary_logloss'][final-1])\n",
    "             , ha='center', va='bottom', fontsize=10)\n",
    "    plt.show()\n",
    "#样例\n",
    "#picture_lgb_loss(metric_dict)    \n",
    "    \n",
    "# 创建训练集，验证集，本地训练集\n",
    "def create_train_valid_test(train_x,train_y,untrain_size=0.1,random=0):\n",
    "    #train_x，总训练特征，dataframe\n",
    "    #train_y，总训练标签，Series\n",
    "    #untrain_size，非训练集比例\n",
    "    #random，随机划分的种子，种子相同即随机划分相同\n",
    "    #划分训练集和非训练集\n",
    "    train_X,valid_X, train_Y, valid_Y = train_test_split(train_x,\n",
    "                                                   train_y,\n",
    "                                                   test_size = untrain_size,\n",
    "                                                   random_state = random)\n",
    "    #将非训练集划分为验证集和本地测试集\n",
    "    valid_X,test_X,valid_Y,test_Y = train_test_split(valid_X,\n",
    "                                                   valid_Y,\n",
    "                                                   test_size = 0.5,\n",
    "                                                   random_state = random)\n",
    "    return train_X,valid_X,test_X, train_Y, valid_Y,test_Y\n",
    "#样例\n",
    "#train_X,valid_X,local_test_X, train_Y, valid_Y,local_test_Y = create_train_valid_test(train_x,train_y)\n",
    "\n",
    "# 创建可训练的lgb数据集\n",
    "def create_lgb_dataset(data,categorical_feature=None,free_raw_data=True):\n",
    "    # list of dataframe，格式：[train_X,valid_X,train_Y,valid_Y]\n",
    "    # categorical_feature：哪些特征要被视为分类特征；注意使用，分类特征和数值特征的处理方法不同\n",
    "    # free_raw_data：是否释放原始数据；当需要使用分类特征是，必须为False\n",
    "    if categorical_feature != None:\n",
    "        free_raw_data=False\n",
    "    train_data = lgb.Dataset(data[0],data[2],categorical_feature=categorical_feature,free_raw_data=free_raw_data)\n",
    "    valid_data = lgb.Dataset(data[1],data[3],categorical_feature=categorical_feature,free_raw_data=free_raw_data)\n",
    "    #返回可训练的训练集与验证集\n",
    "    return train_data,valid_data\n",
    "\n",
    "\n",
    "\n",
    "#可用于early_stop,方式：bst = lgb.train 里面加一个 feval=lgb_f1\n",
    "def lgb_f1_score(y_pred, data):\n",
    "    y_true = data.get_label()  #lgb_data获取label\n",
    "    y_pred = np.round(y_pred) # 默认精度为0，四舍五入\n",
    "    return 'f1', f1_score(y_pred, y_true), True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#未加入初赛\n",
    "%time data = pd.read_feather('feature/combine.bin', use_threads = 12)\n",
    "data = data.drop(['sid'],axis=1)\n",
    "##划分数据：\n",
    "train=data[1000000:6000000]\n",
    "label=train['label']\n",
    "\n",
    "data = data.drop(['label'],axis = 1)\n",
    "train=data[1000000:6000000]\n",
    "test=data[6000000:].reset_index(drop=True)\n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7.5 s\n"
     ]
    }
   ],
   "source": [
    "#加入初赛\n",
    "%time data = pd.read_feather('feature/combine.bin', use_threads = 12)\n",
    "data = data.drop(['sid'],axis=1)\n",
    "##划分数据：\n",
    "train=data[:6000000]\n",
    "label=train['label']\n",
    "\n",
    "data = data.drop(['label'],axis = 1)\n",
    "train=data[:6000000]\n",
    "test=data[6000000:].reset_index(drop=True)\n",
    "del data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lgb训练的模型,传入训练集、标签以及测试集,如果没有指定k折训练，则自动进行1折训练\n",
    "#返回预测的结果\n",
    "def lgb_model(train, label, test, params, k_split = 0, up_load = False):\n",
    "    #如果不上交（本地lgb）\n",
    "    if up_load == False:\n",
    "        # 创建训练集，验证集，本地训练集\n",
    "        train_X,valid_X,local_test_X, train_Y, valid_Y,local_test_Y = create_train_valid_test(train,label)\n",
    "        # 创建可训练的lgb数据集\n",
    "        train_data,valid_data = create_lgb_dataset([train_X,valid_X,train_Y,valid_Y])\n",
    "\n",
    "        if k_split==0:\n",
    "            #不分折训练\n",
    "           \n",
    "            #lgb训练， metric_dict保存训练产生指标\n",
    "            metric_dict = {}\n",
    "            bst = lgb.train(params, train_data,100000,valid_sets = valid_data,early_stopping_rounds=100,\n",
    "                            verbose_eval = 200, callbacks = [lgb.record_evaluation(metric_dict)],feval=lgb_f1)\n",
    "\n",
    "            #输出特征数\n",
    "            print(\"特征数：\",bst.num_feature())\n",
    "            #保存lgb模型\n",
    "            #bst.save_model('lgb.model')\n",
    "            f_importance = bst.feature_importance(importance_type = 'gain')\n",
    "            f_name = bst.feature_name()\n",
    "            print(\"特征重要性(信息增益)：\")\n",
    "            for i in range(len(f_name)):\n",
    "                print(f_name[i]+': '+str(f_importance[i]))\n",
    "            #绘图——loss\n",
    "            picture_lgb_loss(metric_dict)\n",
    "            #评估\n",
    "            cal_f1(binarize(bst.predict(local_test_X)),np.array(local_test_Y))\n",
    "            result = bst.predict(test)\n",
    "            return result\n",
    "\n",
    "        #k折交叉训练\n",
    "        if k_split!=0:\n",
    "\n",
    "            #skf=StratifiedKFold(y,n_folds=5,shuffle=True,random_state=2018)\n",
    "            #5折交叉训练分布  （skf确保训练集，测试集中各类别样本的比例与原始数据集中相同。即skf划分出来的训练集标签一定各个种类都有）\n",
    "            skf = StratifiedKFold(n_splits=k_split,shuffle=True,random_state=98)\n",
    "\n",
    "            ##用于存放测试集概率，k折最后要除以k取平均\n",
    "            result = np.zeros(test.shape[0])  \n",
    "            train_X = np.array(train_X)\n",
    "            train_Y = np.array(train_Y)\n",
    "            \n",
    "            #对于每一折的训练，i计数，tr为训练集所代表的的行数列表，va为验证集所代表的的行数列表\n",
    "            for i,(tr,va) in enumerate(skf.split(train_X,train_Y)):\n",
    "                print(type(train))\n",
    "                print(tr)\n",
    "                print(train_X[tr])\n",
    "                print('fold:',i+1,'training')\n",
    "                dtrain = lgb.Dataset(train_X[tr],train_Y[tr])\n",
    "                dvalid = lgb.Dataset(train_X[va],train_Y[va],reference=dtrain)\n",
    "                ##训练：\n",
    "                metric_dict = {}\n",
    "                bst = lgb.train(params, dtrain, num_boost_round=30000, valid_sets=dvalid,\n",
    "                                verbose_eval=400,early_stopping_rounds=200, callbacks = [lgb.record_evaluation(metric_dict)],\n",
    "                               feval=lgb_f1)\n",
    "\n",
    "                ##预测测试集：\n",
    "                result += bst.predict(local_test_X, num_iteration=bst.best_iteration)\n",
    "                \n",
    "            result/=5\n",
    "            cal_f1(binarize(rsult),np.array(local_test_Y))\n",
    "            \n",
    "            return result\n",
    "    #如果上交，把全部数据丢入训练\n",
    "    if up_load == True:\n",
    "        if k_split == 0 :\n",
    "            #上交的lgb（所有都拿来训练）\n",
    "            train_data_full = lgb.Dataset(train,label)\n",
    "            bst_full = lgb.train(params, train_data_full,3300)\n",
    "            #输出特征数\n",
    "            print(\"特征数：\",bst_full.num_feature())\n",
    "            #输出特征重要性\n",
    "            print(\"特征重要性：\",bst_full.feature_importance(importance_type = 'gain'))\n",
    "            #保存lgb模型\n",
    "            #bst_full.save_model('lgb_full.model')\n",
    "            result = bst.predict(test)\n",
    "            return result\n",
    "        \n",
    "        if k_split!=0:\n",
    "\n",
    "            #skf=StratifiedKFold(y,n_folds=5,shuffle=True,random_state=2018)\n",
    "            #5折交叉训练分布  （skf确保训练集，测试集中各类别样本的比例与原始数据集中相同。即skf划分出来的训练集标签一定各个种类都有）\n",
    "            skf = StratifiedKFold(n_splits=k_split,shuffle=True,random_state=97)\n",
    "\n",
    "            ##用于存放测试集概率，k折最后要除以k取平均\n",
    "            result = np.zeros(test.shape[0])  \n",
    "            train = np.array(train)\n",
    "            label = np.array(label)\n",
    "            #对于每一折的训练，i计数，tr为训练集所代表的的行数，va为验证集所代表的的行数\n",
    "            for i,(tr,va) in enumerate(skf.split(train,label)):\n",
    "                print('fold:',i+1,'training')\n",
    "                dtrain = lgb.Dataset(train[tr],label[tr])\n",
    "                dvalid = lgb.Dataset(train[va],label[va],reference=dtrain)\n",
    "                ##训练：\n",
    "                metric_dict = {}\n",
    "                bst = lgb.train(params, dtrain, num_boost_round=10, valid_sets=dvalid,\n",
    "                                verbose_eval=2,early_stopping_rounds=200, callbacks = [lgb.record_evaluation(metric_dict)],\n",
    "                                feval=lgb_f1_score)\n",
    "                print(\"特征重要性：\",list(zip(list(cols),list(bst.feature_importance(importance_type = 'gain')))))\n",
    "\n",
    "                ##预测测试集：\n",
    "                result += bst.predict(test, num_iteration=bst.best_iteration)\n",
    "                \n",
    "            result /= k_split\n",
    "            return result\n",
    "            \n",
    "        \n",
    "#本地运行不分折训练\n",
    "#lgb_model(train,label,test, k_split = 0, up_load = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 1 training\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[2]\tvalid_0's auc: 0.84934\tvalid_0's f1: 0.76062\n",
      "[4]\tvalid_0's auc: 0.854622\tvalid_0's f1: 0.76062\n",
      "[6]\tvalid_0's auc: 0.853625\tvalid_0's f1: 0.76062\n",
      "[8]\tvalid_0's auc: 0.854442\tvalid_0's f1: 0.76062\n",
      "[10]\tvalid_0's auc: 0.854896\tvalid_0's f1: 0.76062\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9]\tvalid_0's auc: 0.854996\tvalid_0's f1: 0.76062\n",
      "特征重要性： [('h', 4768000.830466747), ('w', 2610011.2204298377), ('ppi', 4327465.291700363), ('orientation', 92685.95234853029)]\n",
      "fold: 2 training\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[2]\tvalid_0's auc: 0.848755\tvalid_0's f1: 0.76062\n",
      "[4]\tvalid_0's auc: 0.853978\tvalid_0's f1: 0.76062\n",
      "[6]\tvalid_0's auc: 0.852918\tvalid_0's f1: 0.76062\n",
      "[8]\tvalid_0's auc: 0.853913\tvalid_0's f1: 0.76062\n",
      "[10]\tvalid_0's auc: 0.854283\tvalid_0's f1: 0.76062\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9]\tvalid_0's auc: 0.854452\tvalid_0's f1: 0.76062\n",
      "特征重要性： [('h', 4768918.360200375), ('w', 2625120.221382618), ('ppi', 4312008.52281189), ('orientation', 93727.83253610134)]\n",
      "fold: 3 training\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[2]\tvalid_0's auc: 0.849558\tvalid_0's f1: 0.76062\n",
      "[4]\tvalid_0's auc: 0.854864\tvalid_0's f1: 0.76062\n",
      "[6]\tvalid_0's auc: 0.853718\tvalid_0's f1: 0.76062\n",
      "[8]\tvalid_0's auc: 0.854597\tvalid_0's f1: 0.76062\n",
      "[10]\tvalid_0's auc: 0.855047\tvalid_0's f1: 0.76062\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9]\tvalid_0's auc: 0.855183\tvalid_0's f1: 0.76062\n",
      "特征重要性： [('h', 4763813.727479041), ('w', 2597894.678100705), ('ppi', 4323474.564986229), ('orientation', 92615.74166864157)]\n",
      "fold: 4 training\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[2]\tvalid_0's auc: 0.849716\tvalid_0's f1: 0.76062\n",
      "[4]\tvalid_0's auc: 0.855106\tvalid_0's f1: 0.76062\n",
      "[6]\tvalid_0's auc: 0.853942\tvalid_0's f1: 0.76062\n",
      "[8]\tvalid_0's auc: 0.855023\tvalid_0's f1: 0.76062\n",
      "[10]\tvalid_0's auc: 0.855371\tvalid_0's f1: 0.76062\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9]\tvalid_0's auc: 0.855563\tvalid_0's f1: 0.76062\n",
      "特征重要性： [('h', 4752439.128398776), ('w', 2617536.7747242153), ('ppi', 4325368.86644268), ('orientation', 93367.75213384628)]\n",
      "fold: 5 training\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[2]\tvalid_0's auc: 0.849643\tvalid_0's f1: 0.76062\n",
      "[4]\tvalid_0's auc: 0.854661\tvalid_0's f1: 0.76062\n",
      "[6]\tvalid_0's auc: 0.853709\tvalid_0's f1: 0.76062\n",
      "[8]\tvalid_0's auc: 0.854482\tvalid_0's f1: 0.76062\n",
      "[10]\tvalid_0's auc: 0.854913\tvalid_0's f1: 0.76062\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[9]\tvalid_0's auc: 0.855044\tvalid_0's f1: 0.76062\n",
      "特征重要性： [('h', 4836050.719514489), ('w', 2550808.219181657), ('ppi', 4301074.992074966), ('orientation', 95321.72838383913)]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#默认参数\n",
    "params1 = {'boosting_type': 'goss',\n",
    "                          'objective': 'binary',\n",
    "                          'metric': ['auc','binary_logloss'],\n",
    "\n",
    "                          'num_leaves': 31,\n",
    "                          #'max_depth' : 7,\n",
    "                          'learning_rate': 0.05,\n",
    "                          #'feature_fraction': 0.9,\n",
    "                  }\n",
    "#k折训练参数，有几个特征就写几个种子\n",
    "params2 = {\n",
    "            'learning_rate': 0.01,\n",
    "            'boosting_type': 'goss',\n",
    "            'objective': 'binary',\n",
    "            'metric': 'auc',\n",
    "            'feature_fraction': 0.8,\n",
    "            #'bagging_fraction': 0.8,#使用goss，bagging-fraction需要为1\n",
    "            'bagging_freq': 5,\n",
    "            'num_leaves': 1000,\n",
    "            'verbose': -1,\n",
    "            'max_depth': -1,\n",
    "          #  'reg_alpha':2.2,\n",
    "          #  'reg_lambda':1.4,\n",
    "            'seed':74,\n",
    "            }\n",
    "\n",
    "result = lgb_model(train,label,test,params2, k_split = 5, up_load = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = binarize(np.array(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(result)\n",
    "#生成答案\n",
    "test_a = pd.read_csv('test_a.txt','\\t')\n",
    "test_b = pd.read_csv('test_b.txt','\\t')\n",
    "test = pd.concat([test_a,test_b],axis=0,sort=False).reset_index(drop=True)\n",
    "\n",
    "sid = pd.DataFrame(test['sid'])\n",
    "final = pd.concat([sid,result], axis=1, join='outer')\n",
    "final.columns = ['sid','label']\n",
    "final.to_csv('lgb_5fold_try.csv',index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
